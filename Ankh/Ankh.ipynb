{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f1107a1a-c52a-4cee-ac54-45de6e20655d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import ankh\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3004cdc-a6a5-474e-98d4-c16c52e95f06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#model, tokenizer = ankh.load_large_model()\n",
    "#model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c17b30d3-c0be-4507-bbcf-fd08ffdcf961",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5EncoderModel(\n",
       "  (shared): Embedding(144, 768)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(144, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(64, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-47): 47 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, tokenizer = ankh.load_base_model()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6096ed9-9eaa-404b-b0fa-a790ad427d9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"training.csv\")\n",
    "df_1 = df[df['Label'] == 1].sample(frac=0.01, random_state=1)\n",
    "df_0 = df[df['Label'] == 0].sample(frac=0.01, random_state=1)\n",
    "\n",
    "df_new = pd.concat([df_1, df_0], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "177aa3fc-ab3c-475d-85de-e532aafdaacf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768\n",
      "768\n",
      "768\n"
     ]
    }
   ],
   "source": [
    "protein_sequences = df['Sequence'][0:3].tolist()\n",
    "embeddings = []\n",
    "for protein_seq in protein_sequences:\n",
    "    temp = [list(seq) for seq in protein_seq]\n",
    "    outputs = tokenizer.batch_encode_plus(temp, \n",
    "                                          add_special_tokens=True, \n",
    "                                          padding=True, \n",
    "                                          is_split_into_words=True, \n",
    "                                          return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        embedding = model(input_ids=outputs['input_ids'], attention_mask=outputs['attention_mask'])[0]\n",
    "        embeddings_1 = embedding[:,1]\n",
    "        embeddings_1_average = []\n",
    "        for n in range(len(embeddings_0[0])):\n",
    "            embeddings_1_average.append(np.mean(embeddings_1[:,n].tolist()))\n",
    "        print(len(embeddings_1_average))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "18e8a6d3-0b16-42ab-9028-20b6c38ab6df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(embeddings_1_average)\n",
    "df.T.to_csv('temp.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "cb13f76d-4466-4952-852a-ffe67082cc6e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0263, -0.0115,  0.0016,  ...,  0.0363,  0.0042, -0.0050],\n",
       "        [-0.0139,  0.0100,  0.0177,  ...,  0.0241, -0.0303, -0.0066],\n",
       "        [-0.0169, -0.0072,  0.0018,  ...,  0.0184, -0.0124, -0.0027],\n",
       "        ...,\n",
       "        [-0.0133,  0.0072,  0.0143,  ...,  0.0230, -0.0211, -0.0002],\n",
       "        [-0.0065, -0.0057, -0.0058,  ...,  0.0235, -0.0086, -0.0093],\n",
       "        [-0.0302,  0.0054,  0.0114,  ...,  0.0272, -0.0167, -0.0192]])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[0][:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "c4ead9e8-f285-481a-ae8e-72850826ba09",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0340,  0.0520, -0.0549,  ..., -0.0168,  0.0137, -0.0351],\n",
       "         [-0.0263, -0.0115,  0.0016,  ...,  0.0363,  0.0042, -0.0050]],\n",
       "\n",
       "        [[-0.0133,  0.0369, -0.0026,  ..., -0.0295,  0.0094, -0.0352],\n",
       "         [-0.0139,  0.0100,  0.0177,  ...,  0.0241, -0.0303, -0.0066]],\n",
       "\n",
       "        [[ 0.0211,  0.0553,  0.0602,  ..., -0.0562, -0.0080, -0.0102],\n",
       "         [-0.0169, -0.0072,  0.0018,  ...,  0.0184, -0.0124, -0.0027]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.0164,  0.0040, -0.0266,  ..., -0.0109,  0.0162,  0.0057],\n",
       "         [-0.0133,  0.0072,  0.0143,  ...,  0.0230, -0.0211, -0.0002]],\n",
       "\n",
       "        [[ 0.0074, -0.0079,  0.0231,  ..., -0.0129, -0.0115, -0.0231],\n",
       "         [-0.0065, -0.0057, -0.0058,  ...,  0.0235, -0.0086, -0.0093]],\n",
       "\n",
       "        [[-0.0221,  0.0514,  0.0105,  ..., -0.0425,  0.0132,  0.0022],\n",
       "         [-0.0302,  0.0054,  0.0114,  ...,  0.0272, -0.0167, -0.0192]]])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "590de273-dc29-4060-b984-3310785683a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "867"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings[0][:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "16573b9b-ce3d-4388-beb4-ce7e18d89525",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "867"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "20701f40-b8ab-48b3-b534-b15e2100d324",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings_1_average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d920f12-ee5f-445e-bcbd-51b7aaa4935e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def dimention_reduction(embeddings_def):\n",
    "    dimention_reduction_result = []\n",
    "    for i in range(len(embeddings_def[0])):\n",
    "        dimention_reduction_result.append(np.mean(embeddings_def[:,i].tolist()))\n",
    "    return dimention_reduction_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6213339-5268-488a-83c5-3bd664ab0715",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for n in range(len(embeddings[0])):\n",
    "    print(n)\n",
    "    if n == 0:\n",
    "        feature_temp = {\n",
    "            '0': dimention_reduction(embeddings[0][n])\n",
    "        }\n",
    "        feature = pd.DataFrame.from_dict(feature_temp, orient='index')\n",
    "    else:\n",
    "        feature.loc[n] = dimention_reduction(embeddings[0][n])\n",
    "#feature.to_csv('feature.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "adb0f6f5-87bb-4b82-90e1-d591979ffc36",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"training.csv\")\n",
    "protein_sequences1 = df['Sequence'].tolist()[0:3]\n",
    "protein_sequences1 = [list(seq) for seq in protein_sequences1]\n",
    "embeddings1 = []\n",
    "for i in range(len(protein_sequences1)):\n",
    "    print(i)\n",
    "    temp = []\n",
    "    temp.append(protein_sequences1[i])\n",
    "    outputs1 = tokenizer.batch_encode_plus(temp, \n",
    "                                          add_special_tokens=True, \n",
    "                                          padding=True, \n",
    "                                          is_split_into_words=True, \n",
    "                                          return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        embeddings1.append(model(input_ids=outputs1['input_ids'], attention_mask=outputs1['attention_mask'])[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3d091016-4df5-45f6-b1ba-8e924cbecd3c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 0.0057, -0.0092, -0.0049,  ..., -0.0095, -0.0169, -0.0296],\n",
       "         [-0.0401, -0.0215, -0.0087,  ..., -0.0215,  0.0336, -0.0066],\n",
       "         [ 0.0176,  0.0188,  0.0912,  ..., -0.0337,  0.0125, -0.0074],\n",
       "         ...,\n",
       "         [-0.0187,  0.0086,  0.0147,  ...,  0.0365, -0.0331, -0.0453],\n",
       "         [-0.0168,  0.0495, -0.0131,  ..., -0.0111,  0.0366, -0.0308],\n",
       "         [-0.0302, -0.0090,  0.0018,  ...,  0.0329, -0.0043, -0.0132]]),\n",
       " tensor([[ 0.0113, -0.0059, -0.0041,  ...,  0.0018, -0.0152, -0.0424],\n",
       "         [-0.0005, -0.0089,  0.0104,  ...,  0.0411,  0.0426, -0.0462],\n",
       "         [-0.0329,  0.0356, -0.0119,  ..., -0.0101,  0.0205, -0.0183],\n",
       "         ...,\n",
       "         [-0.0482,  0.0041,  0.0047,  ...,  0.0146, -0.0225, -0.0258],\n",
       "         [-0.0267,  0.0399,  0.0172,  ...,  0.0292, -0.0051, -0.0552],\n",
       "         [-0.0315, -0.0112,  0.0046,  ...,  0.0332, -0.0093, -0.0109]]),\n",
       " tensor([[ 0.0132, -0.0161, -0.0116,  ..., -0.0338, -0.0224,  0.0028],\n",
       "         [-0.0821,  0.0020, -0.0945,  ..., -0.0712,  0.0019,  0.0300],\n",
       "         [-0.0885, -0.0545, -0.0799,  ..., -0.0739, -0.0015,  0.0647],\n",
       "         ...,\n",
       "         [-0.0187, -0.0078,  0.0812,  ...,  0.0045, -0.0270,  0.0063],\n",
       "         [-0.0275,  0.0776, -0.0221,  ..., -0.0587,  0.0047, -0.0449],\n",
       "         [-0.0385, -0.0023,  0.0008,  ...,  0.0327, -0.0152, -0.0078]])]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e148ef0e-0091-4e2f-8545-a91e8db99aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"training.csv\")\n",
    "protein_sequences = df['Sequence'].tolist()[0:3]\n",
    "protein_sequences = [list(seq) for seq in protein_sequences]\n",
    "\n",
    "outputs = tokenizer.batch_encode_plus(protein_sequences, \n",
    "                                    add_special_tokens=True, \n",
    "                                    padding=True, \n",
    "                                    is_split_into_words=True, \n",
    "                                    return_tensors=\"pt\")\n",
    "with torch.no_grad():\n",
    "    embeddings = model(input_ids=outputs['input_ids'], attention_mask=outputs['attention_mask'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "61ea341e-7f02-4d6c-8149-8de836113dd7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0057, -0.0092, -0.0049,  ..., -0.0095, -0.0169, -0.0296],\n",
       "        [-0.0401, -0.0215, -0.0087,  ..., -0.0215,  0.0336, -0.0066],\n",
       "        [ 0.0176,  0.0188,  0.0912,  ..., -0.0337,  0.0125, -0.0074],\n",
       "        ...,\n",
       "        [-0.0187,  0.0086,  0.0147,  ...,  0.0365, -0.0331, -0.0453],\n",
       "        [-0.0168,  0.0495, -0.0131,  ..., -0.0111,  0.0366, -0.0308],\n",
       "        [-0.0302, -0.0090,  0.0018,  ...,  0.0329, -0.0043, -0.0132]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd67ca4-62f8-4457-bb7d-bb547d418a8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
