{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4ecc422-55b2-4e95-9656-73030dfa26ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from Bio import SeqIO, motifs\n",
    "from Bio.Seq import Seq\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "import torch\n",
    "import json\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3d3f514-bec1-496e-91bb-3b004f354a2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# len = 1259; max4911; min54\n",
    "fasta_pos = \"training/human_train_positive.fasta\"\n",
    "with open(fasta_pos, \"r\") as file1:\n",
    "    sequences_pos = list(SeqIO.parse(file1, \"fasta\"))\n",
    "\n",
    "sequence_data = []\n",
    "for seq_record in sequences_pos:\n",
    "    sequence_data.append({\"Sequence\": str(seq_record.seq),\"Label\":1})\n",
    "df_tra_pos = pd.DataFrame(sequence_data)\n",
    "    \n",
    "fasta_neg = \"training/human_train_negative.fasta\"\n",
    "with open(fasta_neg, \"r\") as file2:\n",
    "    sequences_neg = list(SeqIO.parse(file2, \"fasta\"))\n",
    "\n",
    "sequence_data = []\n",
    "for seq_record in sequences_neg:\n",
    "    sequence_data.append({\"Sequence\": str(seq_record.seq),\"Label\":0})\n",
    "df_tra_neg = pd.DataFrame(sequence_data)\n",
    "\n",
    "training = pd.concat([df_tra_pos, df_tra_neg], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5f51ff28-b31f-4126-848a-bc55eff876ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# len = 315\n",
    "fasta_pos_test = \"testing/human_test_positive.fasta\"\n",
    "with open(fasta_pos_test, \"r\") as file3:\n",
    "    sequences_pos_test = list(SeqIO.parse(file3, \"fasta\"))\n",
    "\n",
    "sequence_data = []\n",
    "for seq_record in sequences_pos_test:\n",
    "    sequence_data.append({\"Sequence\": str(seq_record.seq),\"Label\":1})\n",
    "df_test_pos = pd.DataFrame(sequence_data)\n",
    "    \n",
    "fasta_neg_test = \"testing/human_test_negative.fasta\"\n",
    "with open(fasta_neg_test, \"r\") as file4:\n",
    "    sequences_neg_test = list(SeqIO.parse(file4, \"fasta\"))\n",
    "    \n",
    "sequence_data = []\n",
    "for seq_record in sequences_neg_test:\n",
    "    sequence_data.append({\"Sequence\": str(seq_record.seq),\"Label\":0})\n",
    "df_test_neg = pd.DataFrame(sequence_data)\n",
    "\n",
    "testing = pd.concat([df_test_pos, df_test_neg], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce9554b6-2463-49a5-bdd5-b3b3b1a43885",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1014</th>\n",
       "      <th>1015</th>\n",
       "      <th>1016</th>\n",
       "      <th>1017</th>\n",
       "      <th>1018</th>\n",
       "      <th>1019</th>\n",
       "      <th>1020</th>\n",
       "      <th>1021</th>\n",
       "      <th>1022</th>\n",
       "      <th>1023</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.208095</td>\n",
       "      <td>0.220136</td>\n",
       "      <td>-0.197749</td>\n",
       "      <td>-0.210119</td>\n",
       "      <td>-0.225618</td>\n",
       "      <td>-0.220520</td>\n",
       "      <td>-0.218668</td>\n",
       "      <td>-0.216284</td>\n",
       "      <td>0.202558</td>\n",
       "      <td>-0.212885</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213570</td>\n",
       "      <td>-0.205959</td>\n",
       "      <td>0.218051</td>\n",
       "      <td>-0.216005</td>\n",
       "      <td>-0.214325</td>\n",
       "      <td>-0.200823</td>\n",
       "      <td>0.206391</td>\n",
       "      <td>0.209501</td>\n",
       "      <td>0.195413</td>\n",
       "      <td>-0.214074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.209904</td>\n",
       "      <td>0.222025</td>\n",
       "      <td>-0.199485</td>\n",
       "      <td>-0.211941</td>\n",
       "      <td>-0.227543</td>\n",
       "      <td>-0.222412</td>\n",
       "      <td>-0.220548</td>\n",
       "      <td>-0.218148</td>\n",
       "      <td>0.204329</td>\n",
       "      <td>-0.214726</td>\n",
       "      <td>...</td>\n",
       "      <td>0.215416</td>\n",
       "      <td>-0.207753</td>\n",
       "      <td>0.219927</td>\n",
       "      <td>-0.217867</td>\n",
       "      <td>-0.216176</td>\n",
       "      <td>-0.202581</td>\n",
       "      <td>0.208188</td>\n",
       "      <td>0.211319</td>\n",
       "      <td>0.197132</td>\n",
       "      <td>-0.215923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.210550</td>\n",
       "      <td>0.222705</td>\n",
       "      <td>-0.200102</td>\n",
       "      <td>-0.212592</td>\n",
       "      <td>-0.228237</td>\n",
       "      <td>-0.223093</td>\n",
       "      <td>-0.221223</td>\n",
       "      <td>-0.218817</td>\n",
       "      <td>0.204959</td>\n",
       "      <td>-0.215386</td>\n",
       "      <td>...</td>\n",
       "      <td>0.216077</td>\n",
       "      <td>-0.208393</td>\n",
       "      <td>0.220600</td>\n",
       "      <td>-0.218535</td>\n",
       "      <td>-0.216839</td>\n",
       "      <td>-0.203207</td>\n",
       "      <td>0.208829</td>\n",
       "      <td>0.211969</td>\n",
       "      <td>0.197742</td>\n",
       "      <td>-0.216585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.207671</td>\n",
       "      <td>0.219691</td>\n",
       "      <td>-0.197343</td>\n",
       "      <td>-0.209691</td>\n",
       "      <td>-0.225164</td>\n",
       "      <td>-0.220075</td>\n",
       "      <td>-0.218226</td>\n",
       "      <td>-0.215846</td>\n",
       "      <td>0.202144</td>\n",
       "      <td>-0.212453</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213137</td>\n",
       "      <td>-0.205539</td>\n",
       "      <td>0.217610</td>\n",
       "      <td>-0.215567</td>\n",
       "      <td>-0.213890</td>\n",
       "      <td>-0.200411</td>\n",
       "      <td>0.205970</td>\n",
       "      <td>0.209074</td>\n",
       "      <td>0.195011</td>\n",
       "      <td>-0.213639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.208217</td>\n",
       "      <td>0.220262</td>\n",
       "      <td>-0.197866</td>\n",
       "      <td>-0.210241</td>\n",
       "      <td>-0.225746</td>\n",
       "      <td>-0.220647</td>\n",
       "      <td>-0.218794</td>\n",
       "      <td>-0.216409</td>\n",
       "      <td>0.202678</td>\n",
       "      <td>-0.213009</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213694</td>\n",
       "      <td>-0.206080</td>\n",
       "      <td>0.218176</td>\n",
       "      <td>-0.216129</td>\n",
       "      <td>-0.214450</td>\n",
       "      <td>-0.200942</td>\n",
       "      <td>0.206512</td>\n",
       "      <td>0.209623</td>\n",
       "      <td>0.195529</td>\n",
       "      <td>-0.214197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2513</th>\n",
       "      <td>-0.207851</td>\n",
       "      <td>0.219878</td>\n",
       "      <td>-0.197517</td>\n",
       "      <td>-0.209872</td>\n",
       "      <td>-0.225354</td>\n",
       "      <td>-0.220262</td>\n",
       "      <td>-0.218412</td>\n",
       "      <td>-0.216031</td>\n",
       "      <td>0.202321</td>\n",
       "      <td>-0.212636</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213320</td>\n",
       "      <td>-0.205718</td>\n",
       "      <td>0.217796</td>\n",
       "      <td>-0.215752</td>\n",
       "      <td>-0.214074</td>\n",
       "      <td>-0.200587</td>\n",
       "      <td>0.206149</td>\n",
       "      <td>0.209255</td>\n",
       "      <td>0.195183</td>\n",
       "      <td>-0.213823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2514</th>\n",
       "      <td>-0.209156</td>\n",
       "      <td>0.221244</td>\n",
       "      <td>-0.198767</td>\n",
       "      <td>-0.211187</td>\n",
       "      <td>-0.226747</td>\n",
       "      <td>-0.221630</td>\n",
       "      <td>-0.219771</td>\n",
       "      <td>-0.217377</td>\n",
       "      <td>0.203596</td>\n",
       "      <td>-0.213965</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214653</td>\n",
       "      <td>-0.207011</td>\n",
       "      <td>0.219151</td>\n",
       "      <td>-0.217097</td>\n",
       "      <td>-0.215411</td>\n",
       "      <td>-0.201854</td>\n",
       "      <td>0.207445</td>\n",
       "      <td>0.210567</td>\n",
       "      <td>0.196421</td>\n",
       "      <td>-0.215158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2515</th>\n",
       "      <td>-0.207422</td>\n",
       "      <td>0.219431</td>\n",
       "      <td>-0.197104</td>\n",
       "      <td>-0.209440</td>\n",
       "      <td>-0.224898</td>\n",
       "      <td>-0.219814</td>\n",
       "      <td>-0.217967</td>\n",
       "      <td>-0.215589</td>\n",
       "      <td>0.201900</td>\n",
       "      <td>-0.212199</td>\n",
       "      <td>...</td>\n",
       "      <td>0.212882</td>\n",
       "      <td>-0.205292</td>\n",
       "      <td>0.217351</td>\n",
       "      <td>-0.215310</td>\n",
       "      <td>-0.213636</td>\n",
       "      <td>-0.200170</td>\n",
       "      <td>0.205722</td>\n",
       "      <td>0.208824</td>\n",
       "      <td>0.194774</td>\n",
       "      <td>-0.213384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2516</th>\n",
       "      <td>-0.209384</td>\n",
       "      <td>0.221483</td>\n",
       "      <td>-0.198985</td>\n",
       "      <td>-0.211417</td>\n",
       "      <td>-0.226991</td>\n",
       "      <td>-0.221869</td>\n",
       "      <td>-0.220009</td>\n",
       "      <td>-0.217613</td>\n",
       "      <td>0.203819</td>\n",
       "      <td>-0.214197</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214886</td>\n",
       "      <td>-0.207237</td>\n",
       "      <td>0.219388</td>\n",
       "      <td>-0.217332</td>\n",
       "      <td>-0.215644</td>\n",
       "      <td>-0.202075</td>\n",
       "      <td>0.207671</td>\n",
       "      <td>0.210796</td>\n",
       "      <td>0.196637</td>\n",
       "      <td>-0.215392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2517</th>\n",
       "      <td>-0.209909</td>\n",
       "      <td>0.222034</td>\n",
       "      <td>-0.199486</td>\n",
       "      <td>-0.211946</td>\n",
       "      <td>-0.227554</td>\n",
       "      <td>-0.222421</td>\n",
       "      <td>-0.220557</td>\n",
       "      <td>-0.218156</td>\n",
       "      <td>0.204332</td>\n",
       "      <td>-0.214733</td>\n",
       "      <td>...</td>\n",
       "      <td>0.215423</td>\n",
       "      <td>-0.207757</td>\n",
       "      <td>0.219935</td>\n",
       "      <td>-0.217874</td>\n",
       "      <td>-0.216183</td>\n",
       "      <td>-0.202583</td>\n",
       "      <td>0.208192</td>\n",
       "      <td>0.211324</td>\n",
       "      <td>0.197133</td>\n",
       "      <td>-0.215930</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2518 rows × 1024 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "0    -0.208095  0.220136 -0.197749 -0.210119 -0.225618 -0.220520 -0.218668   \n",
       "1    -0.209904  0.222025 -0.199485 -0.211941 -0.227543 -0.222412 -0.220548   \n",
       "2    -0.210550  0.222705 -0.200102 -0.212592 -0.228237 -0.223093 -0.221223   \n",
       "3    -0.207671  0.219691 -0.197343 -0.209691 -0.225164 -0.220075 -0.218226   \n",
       "4    -0.208217  0.220262 -0.197866 -0.210241 -0.225746 -0.220647 -0.218794   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "2513 -0.207851  0.219878 -0.197517 -0.209872 -0.225354 -0.220262 -0.218412   \n",
       "2514 -0.209156  0.221244 -0.198767 -0.211187 -0.226747 -0.221630 -0.219771   \n",
       "2515 -0.207422  0.219431 -0.197104 -0.209440 -0.224898 -0.219814 -0.217967   \n",
       "2516 -0.209384  0.221483 -0.198985 -0.211417 -0.226991 -0.221869 -0.220009   \n",
       "2517 -0.209909  0.222034 -0.199486 -0.211946 -0.227554 -0.222421 -0.220557   \n",
       "\n",
       "             7         8         9  ...      1014      1015      1016  \\\n",
       "0    -0.216284  0.202558 -0.212885  ...  0.213570 -0.205959  0.218051   \n",
       "1    -0.218148  0.204329 -0.214726  ...  0.215416 -0.207753  0.219927   \n",
       "2    -0.218817  0.204959 -0.215386  ...  0.216077 -0.208393  0.220600   \n",
       "3    -0.215846  0.202144 -0.212453  ...  0.213137 -0.205539  0.217610   \n",
       "4    -0.216409  0.202678 -0.213009  ...  0.213694 -0.206080  0.218176   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "2513 -0.216031  0.202321 -0.212636  ...  0.213320 -0.205718  0.217796   \n",
       "2514 -0.217377  0.203596 -0.213965  ...  0.214653 -0.207011  0.219151   \n",
       "2515 -0.215589  0.201900 -0.212199  ...  0.212882 -0.205292  0.217351   \n",
       "2516 -0.217613  0.203819 -0.214197  ...  0.214886 -0.207237  0.219388   \n",
       "2517 -0.218156  0.204332 -0.214733  ...  0.215423 -0.207757  0.219935   \n",
       "\n",
       "          1017      1018      1019      1020      1021      1022      1023  \n",
       "0    -0.216005 -0.214325 -0.200823  0.206391  0.209501  0.195413 -0.214074  \n",
       "1    -0.217867 -0.216176 -0.202581  0.208188  0.211319  0.197132 -0.215923  \n",
       "2    -0.218535 -0.216839 -0.203207  0.208829  0.211969  0.197742 -0.216585  \n",
       "3    -0.215567 -0.213890 -0.200411  0.205970  0.209074  0.195011 -0.213639  \n",
       "4    -0.216129 -0.214450 -0.200942  0.206512  0.209623  0.195529 -0.214197  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "2513 -0.215752 -0.214074 -0.200587  0.206149  0.209255  0.195183 -0.213823  \n",
       "2514 -0.217097 -0.215411 -0.201854  0.207445  0.210567  0.196421 -0.215158  \n",
       "2515 -0.215310 -0.213636 -0.200170  0.205722  0.208824  0.194774 -0.213384  \n",
       "2516 -0.217332 -0.215644 -0.202075  0.207671  0.210796  0.196637 -0.215392  \n",
       "2517 -0.217874 -0.216183 -0.202583  0.208192  0.211324  0.197133 -0.215930  \n",
       "\n",
       "[2518 rows x 1024 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_feature = pd.read_csv(\"Protein_Bert/feature_train.csv\")\n",
    "training_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3abbde46-ed5c-4504-a6d5-07f3c731d078",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler1 = StandardScaler()\n",
    "scaled_data_train = scaler1.fit_transform(training_feature)\n",
    "training_f = pd.DataFrame(scaled_data_train, columns=training_feature.columns)\n",
    "training_f['Label'] = training['Label'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f817350-941c-4d0e-8470-215ccfd12d12",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1015</th>\n",
       "      <th>1016</th>\n",
       "      <th>1017</th>\n",
       "      <th>1018</th>\n",
       "      <th>1019</th>\n",
       "      <th>1020</th>\n",
       "      <th>1021</th>\n",
       "      <th>1022</th>\n",
       "      <th>1023</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.142026</td>\n",
       "      <td>-0.141646</td>\n",
       "      <td>0.142295</td>\n",
       "      <td>0.141950</td>\n",
       "      <td>0.141484</td>\n",
       "      <td>0.141624</td>\n",
       "      <td>0.141685</td>\n",
       "      <td>0.141779</td>\n",
       "      <td>-0.142179</td>\n",
       "      <td>0.141864</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142085</td>\n",
       "      <td>-0.141725</td>\n",
       "      <td>0.141758</td>\n",
       "      <td>0.141802</td>\n",
       "      <td>0.142233</td>\n",
       "      <td>-0.142077</td>\n",
       "      <td>-0.141971</td>\n",
       "      <td>-0.142396</td>\n",
       "      <td>0.141845</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.633506</td>\n",
       "      <td>0.632739</td>\n",
       "      <td>-0.634142</td>\n",
       "      <td>-0.633377</td>\n",
       "      <td>-0.632376</td>\n",
       "      <td>-0.632705</td>\n",
       "      <td>-0.632830</td>\n",
       "      <td>-0.632982</td>\n",
       "      <td>0.633850</td>\n",
       "      <td>-0.633205</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.633636</td>\n",
       "      <td>0.632868</td>\n",
       "      <td>-0.632998</td>\n",
       "      <td>-0.633110</td>\n",
       "      <td>-0.633964</td>\n",
       "      <td>0.633610</td>\n",
       "      <td>0.633421</td>\n",
       "      <td>0.634288</td>\n",
       "      <td>-0.633129</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.910533</td>\n",
       "      <td>0.911084</td>\n",
       "      <td>-0.910060</td>\n",
       "      <td>-0.910622</td>\n",
       "      <td>-0.911326</td>\n",
       "      <td>-0.911112</td>\n",
       "      <td>-0.911002</td>\n",
       "      <td>-0.910920</td>\n",
       "      <td>0.910289</td>\n",
       "      <td>-0.910747</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.910447</td>\n",
       "      <td>0.910999</td>\n",
       "      <td>-0.910886</td>\n",
       "      <td>-0.910794</td>\n",
       "      <td>-0.910216</td>\n",
       "      <td>0.910459</td>\n",
       "      <td>0.910594</td>\n",
       "      <td>0.909981</td>\n",
       "      <td>-0.910808</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.323948</td>\n",
       "      <td>-0.323956</td>\n",
       "      <td>0.323982</td>\n",
       "      <td>0.323964</td>\n",
       "      <td>0.323952</td>\n",
       "      <td>0.323959</td>\n",
       "      <td>0.323960</td>\n",
       "      <td>0.323936</td>\n",
       "      <td>-0.323956</td>\n",
       "      <td>0.323967</td>\n",
       "      <td>...</td>\n",
       "      <td>0.323949</td>\n",
       "      <td>-0.323945</td>\n",
       "      <td>0.323969</td>\n",
       "      <td>0.323978</td>\n",
       "      <td>0.323962</td>\n",
       "      <td>-0.323949</td>\n",
       "      <td>-0.323956</td>\n",
       "      <td>-0.323955</td>\n",
       "      <td>0.323946</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.089887</td>\n",
       "      <td>-0.089922</td>\n",
       "      <td>0.089820</td>\n",
       "      <td>0.089879</td>\n",
       "      <td>0.089937</td>\n",
       "      <td>0.089922</td>\n",
       "      <td>0.089904</td>\n",
       "      <td>0.089926</td>\n",
       "      <td>-0.089866</td>\n",
       "      <td>0.089886</td>\n",
       "      <td>...</td>\n",
       "      <td>0.089880</td>\n",
       "      <td>-0.089925</td>\n",
       "      <td>0.089889</td>\n",
       "      <td>0.089872</td>\n",
       "      <td>0.089857</td>\n",
       "      <td>-0.089885</td>\n",
       "      <td>-0.089884</td>\n",
       "      <td>-0.089850</td>\n",
       "      <td>0.089912</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2513</th>\n",
       "      <td>0.246673</td>\n",
       "      <td>-0.247227</td>\n",
       "      <td>0.246238</td>\n",
       "      <td>0.246769</td>\n",
       "      <td>0.247467</td>\n",
       "      <td>0.247252</td>\n",
       "      <td>0.247152</td>\n",
       "      <td>0.247045</td>\n",
       "      <td>-0.246441</td>\n",
       "      <td>0.246896</td>\n",
       "      <td>...</td>\n",
       "      <td>0.246588</td>\n",
       "      <td>-0.247124</td>\n",
       "      <td>0.247038</td>\n",
       "      <td>0.246958</td>\n",
       "      <td>0.246364</td>\n",
       "      <td>-0.246600</td>\n",
       "      <td>-0.246747</td>\n",
       "      <td>-0.246134</td>\n",
       "      <td>0.246941</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2514</th>\n",
       "      <td>-0.312748</td>\n",
       "      <td>0.312512</td>\n",
       "      <td>-0.312949</td>\n",
       "      <td>-0.312712</td>\n",
       "      <td>-0.312407</td>\n",
       "      <td>-0.312498</td>\n",
       "      <td>-0.312545</td>\n",
       "      <td>-0.312585</td>\n",
       "      <td>0.312850</td>\n",
       "      <td>-0.312654</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.312787</td>\n",
       "      <td>0.312547</td>\n",
       "      <td>-0.312597</td>\n",
       "      <td>-0.312634</td>\n",
       "      <td>-0.312881</td>\n",
       "      <td>0.312780</td>\n",
       "      <td>0.312720</td>\n",
       "      <td>0.312982</td>\n",
       "      <td>-0.312628</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2515</th>\n",
       "      <td>0.430737</td>\n",
       "      <td>-0.430678</td>\n",
       "      <td>0.430801</td>\n",
       "      <td>0.430734</td>\n",
       "      <td>0.430644</td>\n",
       "      <td>0.430684</td>\n",
       "      <td>0.430688</td>\n",
       "      <td>0.430699</td>\n",
       "      <td>-0.430767</td>\n",
       "      <td>0.430718</td>\n",
       "      <td>...</td>\n",
       "      <td>0.430749</td>\n",
       "      <td>-0.430689</td>\n",
       "      <td>0.430709</td>\n",
       "      <td>0.430716</td>\n",
       "      <td>0.430774</td>\n",
       "      <td>-0.430748</td>\n",
       "      <td>-0.430733</td>\n",
       "      <td>-0.430798</td>\n",
       "      <td>0.430706</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2516</th>\n",
       "      <td>-0.410483</td>\n",
       "      <td>0.410510</td>\n",
       "      <td>-0.410472</td>\n",
       "      <td>-0.410489</td>\n",
       "      <td>-0.410522</td>\n",
       "      <td>-0.410509</td>\n",
       "      <td>-0.410509</td>\n",
       "      <td>-0.410497</td>\n",
       "      <td>0.410479</td>\n",
       "      <td>-0.410498</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.410482</td>\n",
       "      <td>0.410500</td>\n",
       "      <td>-0.410504</td>\n",
       "      <td>-0.410505</td>\n",
       "      <td>-0.410476</td>\n",
       "      <td>0.410481</td>\n",
       "      <td>0.410487</td>\n",
       "      <td>0.410462</td>\n",
       "      <td>-0.410494</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2517</th>\n",
       "      <td>-0.635589</td>\n",
       "      <td>0.636405</td>\n",
       "      <td>-0.634929</td>\n",
       "      <td>-0.635721</td>\n",
       "      <td>-0.636787</td>\n",
       "      <td>-0.636448</td>\n",
       "      <td>-0.636304</td>\n",
       "      <td>-0.636142</td>\n",
       "      <td>0.635248</td>\n",
       "      <td>-0.635902</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.635448</td>\n",
       "      <td>0.636262</td>\n",
       "      <td>-0.636124</td>\n",
       "      <td>-0.636004</td>\n",
       "      <td>-0.635096</td>\n",
       "      <td>0.635495</td>\n",
       "      <td>0.635685</td>\n",
       "      <td>0.634772</td>\n",
       "      <td>-0.635990</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2518 rows × 1025 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "0     0.142026 -0.141646  0.142295  0.141950  0.141484  0.141624  0.141685   \n",
       "1    -0.633506  0.632739 -0.634142 -0.633377 -0.632376 -0.632705 -0.632830   \n",
       "2    -0.910533  0.911084 -0.910060 -0.910622 -0.911326 -0.911112 -0.911002   \n",
       "3     0.323948 -0.323956  0.323982  0.323964  0.323952  0.323959  0.323960   \n",
       "4     0.089887 -0.089922  0.089820  0.089879  0.089937  0.089922  0.089904   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "2513  0.246673 -0.247227  0.246238  0.246769  0.247467  0.247252  0.247152   \n",
       "2514 -0.312748  0.312512 -0.312949 -0.312712 -0.312407 -0.312498 -0.312545   \n",
       "2515  0.430737 -0.430678  0.430801  0.430734  0.430644  0.430684  0.430688   \n",
       "2516 -0.410483  0.410510 -0.410472 -0.410489 -0.410522 -0.410509 -0.410509   \n",
       "2517 -0.635589  0.636405 -0.634929 -0.635721 -0.636787 -0.636448 -0.636304   \n",
       "\n",
       "             7         8         9  ...      1015      1016      1017  \\\n",
       "0     0.141779 -0.142179  0.141864  ...  0.142085 -0.141725  0.141758   \n",
       "1    -0.632982  0.633850 -0.633205  ... -0.633636  0.632868 -0.632998   \n",
       "2    -0.910920  0.910289 -0.910747  ... -0.910447  0.910999 -0.910886   \n",
       "3     0.323936 -0.323956  0.323967  ...  0.323949 -0.323945  0.323969   \n",
       "4     0.089926 -0.089866  0.089886  ...  0.089880 -0.089925  0.089889   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "2513  0.247045 -0.246441  0.246896  ...  0.246588 -0.247124  0.247038   \n",
       "2514 -0.312585  0.312850 -0.312654  ... -0.312787  0.312547 -0.312597   \n",
       "2515  0.430699 -0.430767  0.430718  ...  0.430749 -0.430689  0.430709   \n",
       "2516 -0.410497  0.410479 -0.410498  ... -0.410482  0.410500 -0.410504   \n",
       "2517 -0.636142  0.635248 -0.635902  ... -0.635448  0.636262 -0.636124   \n",
       "\n",
       "          1018      1019      1020      1021      1022      1023  Label  \n",
       "0     0.141802  0.142233 -0.142077 -0.141971 -0.142396  0.141845      1  \n",
       "1    -0.633110 -0.633964  0.633610  0.633421  0.634288 -0.633129      1  \n",
       "2    -0.910794 -0.910216  0.910459  0.910594  0.909981 -0.910808      1  \n",
       "3     0.323978  0.323962 -0.323949 -0.323956 -0.323955  0.323946      1  \n",
       "4     0.089872  0.089857 -0.089885 -0.089884 -0.089850  0.089912      1  \n",
       "...        ...       ...       ...       ...       ...       ...    ...  \n",
       "2513  0.246958  0.246364 -0.246600 -0.246747 -0.246134  0.246941      0  \n",
       "2514 -0.312634 -0.312881  0.312780  0.312720  0.312982 -0.312628      0  \n",
       "2515  0.430716  0.430774 -0.430748 -0.430733 -0.430798  0.430706      0  \n",
       "2516 -0.410505 -0.410476  0.410481  0.410487  0.410462 -0.410494      0  \n",
       "2517 -0.636004 -0.635096  0.635495  0.635685  0.634772 -0.635990      0  \n",
       "\n",
       "[2518 rows x 1025 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e4856d62-e327-4e4d-89d3-36e3b1a9daa4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1015</th>\n",
       "      <th>1016</th>\n",
       "      <th>1017</th>\n",
       "      <th>1018</th>\n",
       "      <th>1019</th>\n",
       "      <th>1020</th>\n",
       "      <th>1021</th>\n",
       "      <th>1022</th>\n",
       "      <th>1023</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2518</th>\n",
       "      <td>-0.057330</td>\n",
       "      <td>0.057044</td>\n",
       "      <td>-0.057499</td>\n",
       "      <td>-0.057257</td>\n",
       "      <td>-0.056927</td>\n",
       "      <td>-0.057027</td>\n",
       "      <td>-0.057068</td>\n",
       "      <td>-0.057163</td>\n",
       "      <td>0.057432</td>\n",
       "      <td>-0.057189</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057367</td>\n",
       "      <td>0.057110</td>\n",
       "      <td>-0.057115</td>\n",
       "      <td>-0.057140</td>\n",
       "      <td>-0.057468</td>\n",
       "      <td>0.057369</td>\n",
       "      <td>0.057284</td>\n",
       "      <td>0.057597</td>\n",
       "      <td>-0.057203</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2519</th>\n",
       "      <td>-1.689691</td>\n",
       "      <td>1.691496</td>\n",
       "      <td>-1.688367</td>\n",
       "      <td>-1.690040</td>\n",
       "      <td>-1.692299</td>\n",
       "      <td>-1.691579</td>\n",
       "      <td>-1.691299</td>\n",
       "      <td>-1.690870</td>\n",
       "      <td>1.688948</td>\n",
       "      <td>-1.690440</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.689400</td>\n",
       "      <td>1.691133</td>\n",
       "      <td>-1.690939</td>\n",
       "      <td>-1.690721</td>\n",
       "      <td>-1.688677</td>\n",
       "      <td>1.689461</td>\n",
       "      <td>1.689934</td>\n",
       "      <td>1.687923</td>\n",
       "      <td>-1.690551</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2520</th>\n",
       "      <td>0.541338</td>\n",
       "      <td>-0.541178</td>\n",
       "      <td>0.541493</td>\n",
       "      <td>0.541324</td>\n",
       "      <td>0.541109</td>\n",
       "      <td>0.541174</td>\n",
       "      <td>0.541211</td>\n",
       "      <td>0.541215</td>\n",
       "      <td>-0.541411</td>\n",
       "      <td>0.541290</td>\n",
       "      <td>...</td>\n",
       "      <td>0.541366</td>\n",
       "      <td>-0.541204</td>\n",
       "      <td>0.541249</td>\n",
       "      <td>0.541280</td>\n",
       "      <td>0.541436</td>\n",
       "      <td>-0.541356</td>\n",
       "      <td>-0.541322</td>\n",
       "      <td>-0.541495</td>\n",
       "      <td>0.541253</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2521</th>\n",
       "      <td>-0.443527</td>\n",
       "      <td>0.442689</td>\n",
       "      <td>-0.444184</td>\n",
       "      <td>-0.443384</td>\n",
       "      <td>-0.442306</td>\n",
       "      <td>-0.442657</td>\n",
       "      <td>-0.442783</td>\n",
       "      <td>-0.442972</td>\n",
       "      <td>0.443882</td>\n",
       "      <td>-0.443195</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.443669</td>\n",
       "      <td>0.442851</td>\n",
       "      <td>-0.442965</td>\n",
       "      <td>-0.443072</td>\n",
       "      <td>-0.444016</td>\n",
       "      <td>0.443640</td>\n",
       "      <td>0.443426</td>\n",
       "      <td>0.444366</td>\n",
       "      <td>-0.443123</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2522</th>\n",
       "      <td>0.199417</td>\n",
       "      <td>-0.199673</td>\n",
       "      <td>0.199209</td>\n",
       "      <td>0.199461</td>\n",
       "      <td>0.199786</td>\n",
       "      <td>0.199689</td>\n",
       "      <td>0.199637</td>\n",
       "      <td>0.199599</td>\n",
       "      <td>-0.199307</td>\n",
       "      <td>0.199518</td>\n",
       "      <td>...</td>\n",
       "      <td>0.199379</td>\n",
       "      <td>-0.199632</td>\n",
       "      <td>0.199586</td>\n",
       "      <td>0.199545</td>\n",
       "      <td>0.199275</td>\n",
       "      <td>-0.199387</td>\n",
       "      <td>-0.199450</td>\n",
       "      <td>-0.199166</td>\n",
       "      <td>0.199545</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3143</th>\n",
       "      <td>-0.042451</td>\n",
       "      <td>0.042811</td>\n",
       "      <td>-0.042192</td>\n",
       "      <td>-0.042521</td>\n",
       "      <td>-0.042977</td>\n",
       "      <td>-0.042822</td>\n",
       "      <td>-0.042777</td>\n",
       "      <td>-0.042678</td>\n",
       "      <td>0.042299</td>\n",
       "      <td>-0.042603</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.042390</td>\n",
       "      <td>0.042737</td>\n",
       "      <td>-0.042704</td>\n",
       "      <td>-0.042665</td>\n",
       "      <td>-0.042248</td>\n",
       "      <td>0.042398</td>\n",
       "      <td>0.042500</td>\n",
       "      <td>0.042092</td>\n",
       "      <td>-0.042619</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3144</th>\n",
       "      <td>1.496922</td>\n",
       "      <td>-1.497555</td>\n",
       "      <td>1.496425</td>\n",
       "      <td>1.497029</td>\n",
       "      <td>1.497837</td>\n",
       "      <td>1.497570</td>\n",
       "      <td>1.497478</td>\n",
       "      <td>1.497338</td>\n",
       "      <td>-1.496649</td>\n",
       "      <td>1.497172</td>\n",
       "      <td>...</td>\n",
       "      <td>1.496815</td>\n",
       "      <td>-1.497429</td>\n",
       "      <td>1.497351</td>\n",
       "      <td>1.497263</td>\n",
       "      <td>1.496566</td>\n",
       "      <td>-1.496823</td>\n",
       "      <td>-1.497005</td>\n",
       "      <td>-1.496288</td>\n",
       "      <td>1.497226</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3145</th>\n",
       "      <td>-1.132691</td>\n",
       "      <td>1.132332</td>\n",
       "      <td>-1.132968</td>\n",
       "      <td>-1.132626</td>\n",
       "      <td>-1.132171</td>\n",
       "      <td>-1.132315</td>\n",
       "      <td>-1.132378</td>\n",
       "      <td>-1.132454</td>\n",
       "      <td>1.132843</td>\n",
       "      <td>-1.132547</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.132750</td>\n",
       "      <td>1.132401</td>\n",
       "      <td>-1.132452</td>\n",
       "      <td>-1.132502</td>\n",
       "      <td>-1.132894</td>\n",
       "      <td>1.132737</td>\n",
       "      <td>1.132644</td>\n",
       "      <td>1.133042</td>\n",
       "      <td>-1.132519</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3146</th>\n",
       "      <td>0.132084</td>\n",
       "      <td>-0.132016</td>\n",
       "      <td>0.132159</td>\n",
       "      <td>0.132080</td>\n",
       "      <td>0.131976</td>\n",
       "      <td>0.132020</td>\n",
       "      <td>0.132023</td>\n",
       "      <td>0.132041</td>\n",
       "      <td>-0.132119</td>\n",
       "      <td>0.132062</td>\n",
       "      <td>...</td>\n",
       "      <td>0.132100</td>\n",
       "      <td>-0.132026</td>\n",
       "      <td>0.132047</td>\n",
       "      <td>0.132057</td>\n",
       "      <td>0.132133</td>\n",
       "      <td>-0.132097</td>\n",
       "      <td>-0.132083</td>\n",
       "      <td>-0.132164</td>\n",
       "      <td>0.132051</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3147</th>\n",
       "      <td>1.390732</td>\n",
       "      <td>-1.390702</td>\n",
       "      <td>1.390739</td>\n",
       "      <td>1.390722</td>\n",
       "      <td>1.390695</td>\n",
       "      <td>1.390699</td>\n",
       "      <td>1.390705</td>\n",
       "      <td>1.390718</td>\n",
       "      <td>-1.390740</td>\n",
       "      <td>1.390716</td>\n",
       "      <td>...</td>\n",
       "      <td>1.390737</td>\n",
       "      <td>-1.390713</td>\n",
       "      <td>1.390705</td>\n",
       "      <td>1.390706</td>\n",
       "      <td>1.390742</td>\n",
       "      <td>-1.390737</td>\n",
       "      <td>-1.390725</td>\n",
       "      <td>-1.390756</td>\n",
       "      <td>1.390720</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>630 rows × 1025 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "2518 -0.057330  0.057044 -0.057499 -0.057257 -0.056927 -0.057027 -0.057068   \n",
       "2519 -1.689691  1.691496 -1.688367 -1.690040 -1.692299 -1.691579 -1.691299   \n",
       "2520  0.541338 -0.541178  0.541493  0.541324  0.541109  0.541174  0.541211   \n",
       "2521 -0.443527  0.442689 -0.444184 -0.443384 -0.442306 -0.442657 -0.442783   \n",
       "2522  0.199417 -0.199673  0.199209  0.199461  0.199786  0.199689  0.199637   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "3143 -0.042451  0.042811 -0.042192 -0.042521 -0.042977 -0.042822 -0.042777   \n",
       "3144  1.496922 -1.497555  1.496425  1.497029  1.497837  1.497570  1.497478   \n",
       "3145 -1.132691  1.132332 -1.132968 -1.132626 -1.132171 -1.132315 -1.132378   \n",
       "3146  0.132084 -0.132016  0.132159  0.132080  0.131976  0.132020  0.132023   \n",
       "3147  1.390732 -1.390702  1.390739  1.390722  1.390695  1.390699  1.390705   \n",
       "\n",
       "             7         8         9  ...      1015      1016      1017  \\\n",
       "2518 -0.057163  0.057432 -0.057189  ... -0.057367  0.057110 -0.057115   \n",
       "2519 -1.690870  1.688948 -1.690440  ... -1.689400  1.691133 -1.690939   \n",
       "2520  0.541215 -0.541411  0.541290  ...  0.541366 -0.541204  0.541249   \n",
       "2521 -0.442972  0.443882 -0.443195  ... -0.443669  0.442851 -0.442965   \n",
       "2522  0.199599 -0.199307  0.199518  ...  0.199379 -0.199632  0.199586   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "3143 -0.042678  0.042299 -0.042603  ... -0.042390  0.042737 -0.042704   \n",
       "3144  1.497338 -1.496649  1.497172  ...  1.496815 -1.497429  1.497351   \n",
       "3145 -1.132454  1.132843 -1.132547  ... -1.132750  1.132401 -1.132452   \n",
       "3146  0.132041 -0.132119  0.132062  ...  0.132100 -0.132026  0.132047   \n",
       "3147  1.390718 -1.390740  1.390716  ...  1.390737 -1.390713  1.390705   \n",
       "\n",
       "          1018      1019      1020      1021      1022      1023  Label  \n",
       "2518 -0.057140 -0.057468  0.057369  0.057284  0.057597 -0.057203      1  \n",
       "2519 -1.690721 -1.688677  1.689461  1.689934  1.687923 -1.690551      1  \n",
       "2520  0.541280  0.541436 -0.541356 -0.541322 -0.541495  0.541253      1  \n",
       "2521 -0.443072 -0.444016  0.443640  0.443426  0.444366 -0.443123      1  \n",
       "2522  0.199545  0.199275 -0.199387 -0.199450 -0.199166  0.199545      1  \n",
       "...        ...       ...       ...       ...       ...       ...    ...  \n",
       "3143 -0.042665 -0.042248  0.042398  0.042500  0.042092 -0.042619      0  \n",
       "3144  1.497263  1.496566 -1.496823 -1.497005 -1.496288  1.497226      0  \n",
       "3145 -1.132502 -1.132894  1.132737  1.132644  1.133042 -1.132519      0  \n",
       "3146  0.132057  0.132133 -0.132097 -0.132083 -0.132164  0.132051      0  \n",
       "3147  1.390706  1.390742 -1.390737 -1.390725 -1.390756  1.390720      0  \n",
       "\n",
       "[630 rows x 1025 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_feature = pd.read_csv(\"Protein_Bert/feature_test.csv\")\n",
    "scaler2 = StandardScaler()\n",
    "scaled_data_test = scaler2.fit_transform(testing_feature)\n",
    "testing_f = pd.DataFrame(scaled_data_test, columns=testing_feature.columns)\n",
    "testing_f['Label'] = testing['Label'].tolist()\n",
    "testing_f.index = pd.RangeIndex(start=2518, stop=3148)\n",
    "testing_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "07a5fb44-e99c-4754-8d46-6cd02bb705bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "79/79 [==============================] - 1s 11ms/step - loss: 0.7054 - accuracy: 0.5210 - val_loss: 0.6810 - val_accuracy: 0.5111\n",
      "Epoch 2/50\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.6934 - accuracy: 0.5199 - val_loss: 0.6662 - val_accuracy: 0.6063\n",
      "Epoch 3/50\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.6934 - accuracy: 0.5330 - val_loss: 0.6701 - val_accuracy: 0.6175\n",
      "Epoch 4/50\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.6913 - accuracy: 0.5322 - val_loss: 0.6886 - val_accuracy: 0.5238\n",
      "Epoch 5/50\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.6952 - accuracy: 0.5254 - val_loss: 0.6852 - val_accuracy: 0.6063\n",
      "Epoch 6/50\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.6919 - accuracy: 0.5218 - val_loss: 0.6755 - val_accuracy: 0.5921\n",
      "Epoch 7/50\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.6907 - accuracy: 0.5302 - val_loss: 0.6781 - val_accuracy: 0.5825\n",
      "Epoch 8/50\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.6952 - accuracy: 0.5278 - val_loss: 0.6844 - val_accuracy: 0.6222\n",
      "Epoch 9/50\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.6924 - accuracy: 0.5401 - val_loss: 0.6789 - val_accuracy: 0.6270\n",
      "Epoch 10/50\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.6910 - accuracy: 0.5250 - val_loss: 0.6775 - val_accuracy: 0.5952\n",
      "Epoch 11/50\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.6914 - accuracy: 0.5187 - val_loss: 0.6797 - val_accuracy: 0.6222\n",
      "Epoch 12/50\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.6903 - accuracy: 0.5286 - val_loss: 0.6720 - val_accuracy: 0.6286\n",
      "Epoch 13/50\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.6906 - accuracy: 0.5314 - val_loss: 0.6766 - val_accuracy: 0.5952\n",
      "Epoch 14/50\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.6905 - accuracy: 0.5346 - val_loss: 0.6732 - val_accuracy: 0.6175\n",
      "Epoch 15/50\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.6905 - accuracy: 0.5282 - val_loss: 0.6791 - val_accuracy: 0.6238\n",
      "Epoch 16/50\n",
      "79/79 [==============================] - 1s 11ms/step - loss: 0.6903 - accuracy: 0.5349 - val_loss: 0.6726 - val_accuracy: 0.6286\n",
      "Epoch 17/50\n",
      "79/79 [==============================] - 1s 11ms/step - loss: 0.6909 - accuracy: 0.5326 - val_loss: 0.6767 - val_accuracy: 0.6206\n",
      "Epoch 18/50\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.6903 - accuracy: 0.5294 - val_loss: 0.6800 - val_accuracy: 0.6111\n",
      "Epoch 19/50\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.6904 - accuracy: 0.5365 - val_loss: 0.6728 - val_accuracy: 0.6302\n",
      "Epoch 20/50\n",
      "79/79 [==============================] - 1s 11ms/step - loss: 0.6911 - accuracy: 0.5409 - val_loss: 0.6717 - val_accuracy: 0.6159\n",
      "Epoch 21/50\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.6919 - accuracy: 0.5326 - val_loss: 0.6831 - val_accuracy: 0.6079\n",
      "Epoch 22/50\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.6908 - accuracy: 0.5286 - val_loss: 0.6738 - val_accuracy: 0.6190\n",
      "Epoch 23/50\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.6911 - accuracy: 0.5258 - val_loss: 0.6762 - val_accuracy: 0.5905\n",
      "Epoch 24/50\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.6908 - accuracy: 0.5274 - val_loss: 0.6729 - val_accuracy: 0.6190\n",
      "Epoch 25/50\n",
      "79/79 [==============================] - 1s 11ms/step - loss: 0.6902 - accuracy: 0.5262 - val_loss: 0.6774 - val_accuracy: 0.6032\n",
      "Epoch 26/50\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.6909 - accuracy: 0.5302 - val_loss: 0.6839 - val_accuracy: 0.5968\n",
      "Epoch 27/50\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.6909 - accuracy: 0.5262 - val_loss: 0.6817 - val_accuracy: 0.6206\n",
      "Epoch 28/50\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.6901 - accuracy: 0.5258 - val_loss: 0.6711 - val_accuracy: 0.6206\n",
      "Epoch 29/50\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.6910 - accuracy: 0.5310 - val_loss: 0.6815 - val_accuracy: 0.6048\n",
      "Epoch 30/50\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.6903 - accuracy: 0.5286 - val_loss: 0.6863 - val_accuracy: 0.5921\n",
      "Epoch 31/50\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.6912 - accuracy: 0.5302 - val_loss: 0.6843 - val_accuracy: 0.6032\n",
      "Epoch 32/50\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.6922 - accuracy: 0.5262 - val_loss: 0.6770 - val_accuracy: 0.5730\n",
      "Epoch 33/50\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.6920 - accuracy: 0.5119 - val_loss: 0.6670 - val_accuracy: 0.6032\n",
      "Epoch 34/50\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.6924 - accuracy: 0.5214 - val_loss: 0.6682 - val_accuracy: 0.6143\n",
      "Epoch 35/50\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.6934 - accuracy: 0.5246 - val_loss: 0.6783 - val_accuracy: 0.6222\n",
      "Epoch 36/50\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.6914 - accuracy: 0.5334 - val_loss: 0.6778 - val_accuracy: 0.6159\n",
      "Epoch 37/50\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.6905 - accuracy: 0.5409 - val_loss: 0.6762 - val_accuracy: 0.6159\n",
      "Epoch 38/50\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.6900 - accuracy: 0.5286 - val_loss: 0.6819 - val_accuracy: 0.6190\n",
      "Epoch 39/50\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.6915 - accuracy: 0.5159 - val_loss: 0.6815 - val_accuracy: 0.6143\n",
      "Epoch 40/50\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.6909 - accuracy: 0.5310 - val_loss: 0.6765 - val_accuracy: 0.6175\n",
      "Epoch 41/50\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.6912 - accuracy: 0.5294 - val_loss: 0.6798 - val_accuracy: 0.6222\n",
      "Epoch 42/50\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.6903 - accuracy: 0.5258 - val_loss: 0.6808 - val_accuracy: 0.6079\n",
      "Epoch 43/50\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.6910 - accuracy: 0.5322 - val_loss: 0.6762 - val_accuracy: 0.6238\n",
      "Epoch 44/50\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.6910 - accuracy: 0.5306 - val_loss: 0.6750 - val_accuracy: 0.6286\n",
      "Epoch 45/50\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.6902 - accuracy: 0.5199 - val_loss: 0.6829 - val_accuracy: 0.5841\n",
      "Epoch 46/50\n",
      "79/79 [==============================] - 1s 11ms/step - loss: 0.6916 - accuracy: 0.5298 - val_loss: 0.6798 - val_accuracy: 0.6190\n",
      "Epoch 47/50\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.6908 - accuracy: 0.5242 - val_loss: 0.6778 - val_accuracy: 0.6143\n",
      "Epoch 48/50\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.6906 - accuracy: 0.5314 - val_loss: 0.6787 - val_accuracy: 0.6206\n",
      "Epoch 49/50\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.6911 - accuracy: 0.5207 - val_loss: 0.6872 - val_accuracy: 0.5778\n",
      "Epoch 50/50\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.6914 - accuracy: 0.5314 - val_loss: 0.6805 - val_accuracy: 0.6175\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f1464147ca0>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPooling2D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "X_train_ini = training_f.drop('Label', axis=1).values\n",
    "y_train_ini = training_f['Label'].values\n",
    "\n",
    "X_train = X_train_ini.reshape(-1, 32, 32, 1)\n",
    "y_train = to_categorical(y_train_ini)\n",
    "\n",
    "X_test_ini = testing_f.drop('Label', axis=1).values\n",
    "y_test_ini = testing_f['Label'].values\n",
    "\n",
    "X_test = X_test_ini.reshape(-1, 32, 32, 1)\n",
    "y_test = to_categorical(y_test_ini)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=3, input_shape=(32, 32, 1)))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(64, kernel_size=3))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(128, kernel_size=3))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(2, activation='softmax')) \n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b3394e6d-6e38-4292-a8b0-0bdde6b057b1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "79/79 [==============================] - 1s 12ms/step - loss: 0.7136 - accuracy: 0.5258 - val_loss: 0.6706 - val_accuracy: 0.5238\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 1s 12ms/step - loss: 0.6940 - accuracy: 0.5111 - val_loss: 0.6668 - val_accuracy: 0.5984\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 1s 12ms/step - loss: 0.6917 - accuracy: 0.5171 - val_loss: 0.6791 - val_accuracy: 0.6286\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 1s 12ms/step - loss: 0.6916 - accuracy: 0.5266 - val_loss: 0.6740 - val_accuracy: 0.6206\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 1s 12ms/step - loss: 0.6910 - accuracy: 0.5342 - val_loss: 0.6824 - val_accuracy: 0.6095\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 1s 11ms/step - loss: 0.6928 - accuracy: 0.5274 - val_loss: 0.6829 - val_accuracy: 0.6190\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 1s 11ms/step - loss: 0.6929 - accuracy: 0.5338 - val_loss: 0.6722 - val_accuracy: 0.6000\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 1s 12ms/step - loss: 0.6918 - accuracy: 0.5318 - val_loss: 0.6853 - val_accuracy: 0.6000\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 1s 13ms/step - loss: 0.6920 - accuracy: 0.5210 - val_loss: 0.6765 - val_accuracy: 0.5794\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 1s 12ms/step - loss: 0.6913 - accuracy: 0.5290 - val_loss: 0.6808 - val_accuracy: 0.5937\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f13d8c3ef50>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_ini = training_f.drop('Label', axis=1).values\n",
    "y_train_ini = training_f['Label'].values\n",
    "\n",
    "X_train = X_train_ini.reshape(-1, 32, 32, 1)\n",
    "y_train = to_categorical(y_train_ini)\n",
    "\n",
    "X_test_ini = testing_f.drop('Label', axis=1).values\n",
    "y_test_ini = testing_f['Label'].values\n",
    "\n",
    "X_test = X_test_ini.reshape(-1, 32, 32, 1)\n",
    "y_test = to_categorical(y_test_ini)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=3, input_shape=(32, 32, 1)))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(64, kernel_size=3))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(128, kernel_size=3))\n",
    "model.add(Conv2D(256, kernel_size=3))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fe3771f6-ad46-4b7d-b602-5df99ded060a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "79/79 [==============================] - 1s 11ms/step - loss: 0.7112 - accuracy: 0.5199 - val_loss: 0.6817 - val_accuracy: 0.6286\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.6962 - accuracy: 0.5195 - val_loss: 0.6671 - val_accuracy: 0.6175\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.6966 - accuracy: 0.5207 - val_loss: 0.6834 - val_accuracy: 0.6016\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.6920 - accuracy: 0.5409 - val_loss: 0.6763 - val_accuracy: 0.6270\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.6919 - accuracy: 0.5270 - val_loss: 0.6791 - val_accuracy: 0.6206\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.6915 - accuracy: 0.5294 - val_loss: 0.6660 - val_accuracy: 0.6111\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.6915 - accuracy: 0.5353 - val_loss: 0.6779 - val_accuracy: 0.5889\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.6913 - accuracy: 0.5286 - val_loss: 0.6740 - val_accuracy: 0.6143\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.6910 - accuracy: 0.5298 - val_loss: 0.6740 - val_accuracy: 0.6190\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 1s 11ms/step - loss: 0.6916 - accuracy: 0.5187 - val_loss: 0.6822 - val_accuracy: 0.6063\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f13d8a4ed70>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=3, input_shape=(32, 32, 1)))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(64, kernel_size=3))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(128, kernel_size=3))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(2, activation='sigmoid')) \n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3acc2fe-0264-497e-bad6-8a0c8efa6552",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
